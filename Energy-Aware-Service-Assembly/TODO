METEPOLITICA:

- Rank: metric  
- alfa: weight of history. 1=no history
- h: exploration parameter. h=infinity is greedy
- sng: lower is better (-) or higher is better (+)


POLITICHE:

Random: STRATEGY.equals("random")  
- Rank:   
- alfa: 
- h: 0
- sng:
- TODO: Nothing

Local: (STRATEGY.equals("local_energy"))
- Rank: L  
- alfa: variabile (1, 0.5)
- h: variabile --> h=infinito (politica greedy), h=costante (1? oppure 2?)
- sng: -
- TODO: estendere per mantenere efficiency estimator ed h?

Overall: (STRATEGY.equals("overall_energy"))
- Rank: O 
- alfa: variabile (1, 0.5)
- h: variabile --> h=infinito (politica greedy), h=costante (1? oppure 2?)
- sng: -
- TODO: estendere per mantenere efficiency estimator ed h. Sembrava che andasse troppo bene, controllare.

Energy Aware (Learning):
- Testare al variare come le precedenti
- TODO: Riscriverla mettendo il suo ee

Residual Life:(STRATEGY.equals("weighted_random"))
- Rank: rl
- alfa: variabile come le altre
- h: variabile come le altre
- sng: -
- TODO: ???

Energy Balance: (STRATEGY.equals("fair_energyBP"))
- TODO: Vedere dove sta e se quel progetto contiene cose che non sono nel master
- Rank: ee
- alfa: variabile (1, 0.5)
- h: variabile --> h=infinito (politica greedy), h=costante (1? oppure 2?)
- sng: -
- TODO: stare attenti a quale chiamare: P (panel) ,BP (battery panel)


SCENARIO E PARAMETRI:

RETE:
- Battery? Number of nodes?
- Ripartiamo dagli scenari statici della tesi di Francesca

Scenario A:
- nodi
- ecc
- ecc

Scenario B:
- nodi
- ecc
- ecc

Scenario C:
- nodi
- ecc
- ecc


MIRKO:
- Ho implementato così: ee and K li prendo non dal servizio ma dalla reputation direttamente (per local ed overall template)
- bisogna controllare come si comporta il segno del template per le nostre politiche. Abbiamo detto che lower is better (-) and higher is better (+).
Però mi ricordo che quando il valore è tra 0 ed 1 l'opposto vale. Dobbiamo vedere la metrica dove applichiamo questo H (in Overload application)
